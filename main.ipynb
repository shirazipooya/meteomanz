{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Station ∆        Date UTC time  Temp. (ºC) Rel. Hum. (%)  \\\n",
      "0      ABADAN  08/02/2006      21Z        20.0           81%   \n",
      "1      ABADAN  08/02/2006      18Z        20.2           81%   \n",
      "2      ABADAN  08/02/2006      15Z        21.6           75%   \n",
      "3      ABADAN  08/02/2006      12Z        24.4           49%   \n",
      "4      ABADAN  08/02/2006      09Z        21.4           70%   \n",
      "..        ...         ...      ...         ...           ...   \n",
      "295   KONARAK  08/02/2006      06Z        23.6           61%   \n",
      "296     MAKKO  08/02/2006      18Z        -3.4           94%   \n",
      "297     MAKKO  08/02/2006      15Z        -2.4           84%   \n",
      "298     MAKKO  08/02/2006      12Z         NaN            0%   \n",
      "299     MAKKO  08/02/2006      09Z        -0.6           77%   \n",
      "\n",
      "    Pressure/ Geopot.   Wind dir Wins speed (Km/h) Clouds Low clouds  \\\n",
      "0                   -  330º (NW)              18.0    8/8          -   \n",
      "1                   -  090º (E )              14.4    6/8          -   \n",
      "2                   -  060º (NE)              10.8    6/8          -   \n",
      "3                   -  120º (SE)              21.6    7/8          -   \n",
      "4                   -  120º (SE)              36.0    4/8          -   \n",
      "..                ...        ...               ...    ...        ...   \n",
      "295                 -      calm.               NaN    0/8          -   \n",
      "296                 -      calm.               NaN    4/8          -   \n",
      "297                 -      calm.               NaN    7/8          -   \n",
      "298                 -   000º (N)              57.6    1/8          -   \n",
      "299                 -      calm.               NaN    7/8          -   \n",
      "\n",
      "    Medium clouds High clouds Prec. (mm) Max temp. (ºC) Min temp. (ºC)  \\\n",
      "0               -           -          -              -              -   \n",
      "1               -           -          -              -              -   \n",
      "2               -           -          -              -              -   \n",
      "3               -           -          -              -              -   \n",
      "4               -           -          -              -              -   \n",
      "..            ...         ...        ...            ...            ...   \n",
      "295             -           -          -              -              -   \n",
      "296             -           -          -              -              -   \n",
      "297             -           -          -              -              -   \n",
      "298             -           -          -              -              -   \n",
      "299             -           -          -              -              -   \n",
      "\n",
      "           Conditions  \n",
      "0            Overcast  \n",
      "1              Cloudy  \n",
      "2              Cloudy  \n",
      "3              Cloudy  \n",
      "4    Scattered clouds  \n",
      "..                ...  \n",
      "295             Clear  \n",
      "296  Scattered clouds  \n",
      "297            Cloudy  \n",
      "298        Few clouds  \n",
      "299            Cloudy  \n",
      "\n",
      "[300 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "from utils import Meteomanz\n",
    "\n",
    "\n",
    "\n",
    "m = Meteomanz()\n",
    "url = \"http://www.meteomanz.com/sy1?ty=hp&l=1&cou=2060&ind=00000&d1=08&m1=02&y1=2006&h1=00Z&d2=08&m2=02&y2=2006&h2=23Z&so=001&np=1\"\n",
    "\n",
    "# Send a GET request to fetch the HTML content\n",
    "response = requests.get(url=url, headers=m.header(), timeout=20)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Wrap the HTML content in io.StringIO\n",
    "    html_content = response.content.decode('utf-8', errors='ignore')\n",
    "    html_io = io.StringIO(html_content)\n",
    "\n",
    "    # Read the HTML content and extract tables into a list of DataFrames\n",
    "    tables = pd.read_html(html_io)\n",
    "\n",
    "    # Assuming you want to work with the first table found on the page\n",
    "    if tables:\n",
    "        df = tables[0]  # Extract the first table as a DataFrame\n",
    "        print(df)  # Print the DataFrame\n",
    "    else:\n",
    "        print(\"No tables found on the page.\")\n",
    "else:\n",
    "    print(\"Failed to fetch the HTML content. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temp: ºC, Precip: mm, Presure: Hpa, Wind Speed: Km/h, Sunshine: hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder = \"output/day\"\n",
    "list_csv_files = os.listdir(path=raw_data_folder)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for namefile in list_csv_files:\n",
    "    f_name = f\"{raw_data_folder}/{namefile}\"\n",
    "    df = pd.read_csv(filepath_or_buffer=f_name, na_values=[\"-\", \"Ip\"])\n",
    "    data = pd.concat(objs=[data, df])\n",
    "\n",
    "data = data.rename(\n",
    "    {\n",
    "        'Estación ∆' : \"Station_Name\",\n",
    "        'Fecha' : \"Date\",\n",
    "        'T. med. (ºC)' : \"Tmean\",\n",
    "        'T. max (ºC)' : \"Tmax\",\n",
    "        'T. min (ºC)' : \"Tmin\",\n",
    "        'Prec. (mm)' : \"Precip\",\n",
    "        'Presión/ Geopot.' : \"Presure\",\n",
    "        'Dir. vi.' : \"Wind_Dir\",\n",
    "        'Vel. vi. (Km/h)' : \"Wind_Speed\",\n",
    "        'Nub.' : \"Cloud_Condition\",\n",
    "        'Prof. nieve (cm)' : \"Prof\",\n",
    "        'Insolac. (horas)' : \"Sun_Shine\",\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "\n",
    "data.sort_values([\"Station_Name\", \"Date\"], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def rep(x):\n",
    "    try:\n",
    "        x = x.replace(\" Hpa\", \"\").strip()\n",
    "        if \"m\" in x:\n",
    "            x = re.sub(r\"m(.*)\", \"\", x).strip()\n",
    "    except:\n",
    "        pass\n",
    "    return x\n",
    "\n",
    "\n",
    "data['Presure'] = data['Presure'].apply(rep)\n",
    "data['Presure'] = data[\"Presure\"].apply(float)\n",
    "\n",
    "data['Wind_Dir'] = data[\"Wind_Dir\"].apply(lambda x : re.sub(r\"º(.*)\", \"\", x).strip() if pd.notnull(x) else x)\n",
    "data['Wind_Dir'] = data[\"Wind_Dir\"].apply(lambda x : int(x) if pd.notnull(x) else x)\n",
    "\n",
    "data.drop(columns=[\"Cloud_Condition\", \"Prof\"], inplace=True)\n",
    "\n",
    "data.to_csv(path_or_buf=\"./output/daily.csv\", header=True, index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"daily.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"daily.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data_mashhad = data[data[\"Station_Name\"] == \"MASHHAD\"]\n",
    "\n",
    "data_mashhad.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mashhad = data_mashhad[data_mashhad[\"Date\"] >= \"1951-01-01\"]\n",
    "data_mashhad = data_mashhad[data_mashhad[\"Date\"] <= \"2023-12-31\"]\n",
    "\n",
    "\n",
    "\n",
    "data_mashhad.to_csv(path_or_buf=\"./output/mashhad_2000_2023.csv\", header=True, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tmean</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Precip</th>\n",
       "      <th>Presure</th>\n",
       "      <th>Wind_Dir</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Sun_Shine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>14.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>10.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>10.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.2</td>\n",
       "      <td>253.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>10.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1014.1</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8749</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>9.9</td>\n",
       "      <td>17.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1026.3</td>\n",
       "      <td>117.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8750</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>311.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8751</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1030.8</td>\n",
       "      <td>139.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1028.6</td>\n",
       "      <td>153.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8753</th>\n",
       "      <td>MASHHAD</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>7.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>152.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8754 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Station_Name       Date  Tmean  Tmax  Tmin  Precip  Presure  Wind_Dir  \\\n",
       "0         MASHHAD 2000-01-01    NaN   NaN   4.6     NaN      NaN       NaN   \n",
       "1         MASHHAD 2000-01-02   14.8  19.2  10.4     0.0   1017.2      59.0   \n",
       "2         MASHHAD 2000-01-03   10.8  19.2   2.4     0.0   1013.3      79.0   \n",
       "3         MASHHAD 2000-01-04   10.6  18.0   3.2     0.0   1012.2     253.0   \n",
       "4         MASHHAD 2000-01-05   10.6  13.0   8.2     0.0   1014.1     250.0   \n",
       "...           ...        ...    ...   ...   ...     ...      ...       ...   \n",
       "8749      MASHHAD 2023-12-27    9.9  17.2   2.7     0.0   1026.3     117.0   \n",
       "8750      MASHHAD 2023-12-28   11.0  20.8   1.2     0.0   1016.8     311.0   \n",
       "8751      MASHHAD 2023-12-29    2.6   3.6   1.6     NaN   1030.8     139.0   \n",
       "8752      MASHHAD 2023-12-30    6.2  11.9   0.4     0.0   1028.6     153.0   \n",
       "8753      MASHHAD 2023-12-31    7.6  16.2  -1.0     0.0   1021.8     152.0   \n",
       "\n",
       "      Wind_Speed  Sun_Shine  \n",
       "0            NaN        8.7  \n",
       "1            5.0        8.6  \n",
       "2            9.0        7.0  \n",
       "3            7.0        1.6  \n",
       "4            5.0        0.8  \n",
       "...          ...        ...  \n",
       "8749         9.0        NaN  \n",
       "8750         8.0        NaN  \n",
       "8751        21.0        NaN  \n",
       "8752         8.0        NaN  \n",
       "8753         9.0        NaN  \n",
       "\n",
       "[8754 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mashhad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [JANUARY, 2000]\n",
       "1       [FEBRUARY, 2000]\n",
       "2          [MARCH, 2000]\n",
       "3          [APRIL, 2000]\n",
       "4            [MAY, 2000]\n",
       "             ...        \n",
       "287     [DECEMBER, 2023]\n",
       "288      [JANUARY, 2024]\n",
       "289     [FEBRUARY, 2024]\n",
       "290        [MARCH, 2024]\n",
       "291    [PERIOD, SUMMARY]\n",
       "Name: Month ∆, Length: 292, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"output/month/40845-2024-03.csv\")[\"Month ∆\"].apply(lambda x : x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psh2610\\AppData\\Local\\Temp\\ipykernel_24288\\2049596766.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(pd.read_csv(\"output/month/40845-2024-03.csv\")[\"Month ∆\"])\n"
     ]
    },
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: PERIOD SUMMARY, at position 291",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/month/40845-2024-03.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMonth ∆\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\psh2610\\w\\meteomanz\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\psh2610\\w\\meteomanz\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\psh2610\\w\\meteomanz\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:553\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:666\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: PERIOD SUMMARY, at position 291"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.to_datetime(pd.read_csv(\"output/month/40845-2024-03.csv\")[\"Month ∆\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 1, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a panda dataframe with columns name `Month ∆` and value sample `DECEMBER 2022`\n",
    "import pandas as pd\n",
    "import datetime\n",
    "month_dict = {\n",
    "    \"January\": 1,\n",
    "    \"February\": 2,\n",
    "    \"March\": 3,\n",
    "    \"April\": 4,\n",
    "    \"May\": 5,\n",
    "    \"June\": 6,\n",
    "    \"July\": 7,\n",
    "    \"August\": 8,\n",
    "    \"September\": 9,\n",
    "    \"October\": 10,\n",
    "    \"November\": 11,\n",
    "    \"December\": 12,\n",
    "}\n",
    "df = pd.DataFrame(data={\"Month ∆\": [\"DECEMBER 2022\", \"JANUARY 2023\", \"FEBRUARY 2023\", \"MARCH 2023\", \"APRIL 2023\", \"MAY 2023\", \"JUNE 2023\", \"JULY 2023\", \"AUGUST 2023\", \"SEPTEMBER 2023\", \"OCTOBER 2023\", \"NOVEMBER 2023\", \"DECEMBER 2023\"]})\n",
    "df[['month', 'year']] = df['Month ∆'].str.split(' ', expand=True)\n",
    "df[\"year\"] = df[\"year\"].map(lambda x: int(x))\n",
    "df[\"month\"] = df[\"month\"].map(lambda x: month_dict[x.capitalize()])\n",
    "df = df.sort_values(by=[\"year\", \"month\"], ascending=[False, False])\n",
    "datetime.date(df[\"year\"].iloc[0] + 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2014-11',\n",
       " '2014-12',\n",
       " '2015-01',\n",
       " '2015-02',\n",
       " '2015-03',\n",
       " '2015-04',\n",
       " '2015-05',\n",
       " '2015-06',\n",
       " '2015-07',\n",
       " '2015-08',\n",
       " '2015-09',\n",
       " '2015-10',\n",
       " '2015-11',\n",
       " '2015-12',\n",
       " '2016-01']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.date_range('2014-10-10','2016-01-07', \n",
    "              freq='MS').strftime(\"%Y-%m\").tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
